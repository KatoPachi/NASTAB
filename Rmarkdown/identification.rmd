---
title: "理想的なデータセットでのIdentificationを考える"
author: Hiroki Kato
output:
  html_document:
    toc: true
    toc_float: true
params:
  preview: true
---


```{r include = FALSE, eval = params$preview}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo = TRUE,
  cache = FALSE,
  include = TRUE,
  fig.width = 10
)

library(here)
knitr::opts_knit$set(
  root.dir = here::here()
)

options(
  knitr.kable.NA = " ",
  knitr.table.format = "html",
  modelsummary_stars_note = FALSE
)
```

```{r include = FALSE, eval = params$preview}
library(xfun)
xfun::pkg_attach2(c(
  "tidyverse", "rlist", "modelsummary", "kableExtra",
  "estimatr", "fixest"
))

lapply(Sys.glob(file.path("script/R/functions", "*.r")), source)
```


我々が知りたいことは、**控除を申請していない人が申請するならば、どれくらいの寄付を価格インセンティブで増やせるか？**

# Data Generating Process

## Modeling Counterfactuals

寄付額は寄付の相対価格$p_i$（後に示すが、**first-priceを用いて意思決定をしていると仮定する**）と所得$y_i$に依存して決まるとする。
というか、分析者は価格と所得のみ観察できるとする。
寄付額（の対数値）は以下のように決まる

$$ \ln g_i = \epsilon_{pi} \ln p_i + 0.4 \ln y_i + u_i $$

- 価格弾力性$\epsilon_{pi}$は個人によって異なる（random coefficient model）
  - $[-1.6, -0.8]$の範囲で一様に分布し、外生的に決まる
- 所得弾力性はすべての個人について0.4とする
- 個人の所得は$[0, 32000]$の範囲で一様に分布し、外生的に決まる
- 価格$p_i$は所得$y_i$と寄付控除を申請したかどうかを示す二値変数$R_i$で決まる、すなわち、$p_i = 1 - R_i \cdot \tau(y_i)$
  - 寄付額に依存しないfirst-priceを用いる。last-priceはモデル化が複雑になるのでやめた
  - $\tau(\cdot)$は2013年の韓国の所得税率を使用する。
- これ以外の要因を誤差項$u_i$で集約し、$N(0, 1)$に従うとする。

仮に寄付控除を申請した場合の寄付額$g_{i1}$とそうでない場合の寄付額$g_{i0}$を以下のように作る

```{r}
set.seed(1205)

# observation
n <- 20000

# price elasticity, income and error term
eps <- runif(n, -1.6, -0.8)
y <- runif(n, 0, 30000)
u <- rnorm(n)

# average tax rate function
atr13 <- function(x) {
  dplyr::case_when(
    x <= 1200 ~ 0.07,
    x <= 4600 ~ 0.15,
    x <= 8800 ~ 0.25,
    x <= 30000 ~ 0.36,
    TRUE ~ 0.38
  )
}

# first-price of giving
p <- 1 - atr13(y)

# log donations if applying for a tax deduction
g1 <- eps * log(p) + 0.4 * log(y) + u

# log donations if not applying for a tax deduction
g0 <- eps * log(1) + 0.4 * log(y) + u
```

## Modeling of Choice of Tax Deduction

個人は税負担と寄付控除の申請コストを最小化するように行動する。すなわち、

$$ R_i = 1[T(y_i) > T(y_i - g_{i1}) + C_i] $$

- 寄付控除を申請しないときの税負担は$T(y_i) = \tau(y_i) \cdot y_i$となる
- 寄付控除を申請するときの税負担は$T(y_i - g_{i1}) = \tau(y_i - g_{i1}) \cdot (y_i - g_{i1})$となる
- 申請コストは$C_i = 80 - 40 \cdot Z_i + v_i$とする
  - $Z_i$は$Cov(u_i, Z_i) = Cov(v_i, Z_i) = 0$を満たす寄付控除の申請コストを下げる二値変数で、確率0.5のベルヌーイ分布に従う
  - 観察できない申請コストの要因は$v_i$に集約し、$N(0, 10)$に従うとする

```{r}
# applying cost
z <- sample(c(1, 0), size = n, replace = TRUE, prob = c(0.5, 0.5))
v <- rnorm(n, sd = sqrt(10))
cost <- 80 - 40 * z + v

# choice of tax deduction
r <- 1 * (atr13(y) * y > atr13(y - exp(g1)) * (y - exp(g1)) + cost)
```

## Observed Dataset

観測できるデータは以下の通りになる

1. 寄付の対数値：$\ln g_i = R_i \ln g_{i1} + (1 - R_i) \ln g_{i0}$
1. 所得の対数値：$\ln y$
1. 実際の寄付価格：$1 - R_i \cdot \tau(y_i)$
1. 控除を申請した場合の寄付価格：$1 - \tau(y_i)$
1. 控除を申請したかどうか：$R_i$
1. 申請コストを下げる変数：$Z_i$

```{r}
# observed dataset
dt <- tibble::tibble(
  ln_g = r * g1 + (1 - r) * g0,
  ln_y = log(y),
  real_p = 1 - r * atr13(y),
  p = p,
  r = r,
  z = z
)

head(dt)
```

# Evaluation Problem

## Parameter of Interest

我々の関心とするところは、**申請コストを明示的に計量モデルに組み込んだうえで、価格インセンティブの効果を推定すること**。
その効果を推定するために、二つのパラメータが考えられる

1. 価格弾力性 $\epsilon_{pi}$
1. 控除申請の寄付に対する効果 $\beta_i = \ln g_{i1} - \ln g_{i0}$

価格弾力性が個人によって異なることを想定しているので、
関心のある二つのパラメータは個人間で異なる（random coefficient model）。
以下の二つのグラフは寄付控除を申請したかどうかでサブサンプルを作り、
その密度関数を推定したものである。

```{r}
tibble(eps = eps, r = r) %>%
  mutate(r = factor(r, labels = c("していない", "した"))) %>%
  ggplot(aes(x = eps)) +
    geom_density(aes(linetype = r)) +
    labs(x = "弾力性", y = "密度", linetype = "寄付申請") +
    ggtemp()

b <- g1 - g0

tibble(beta = b, r = r) %>%
  mutate(r = factor(r, labels = c("していない", "した"))) %>%
  ggplot(aes(x = beta)) +
    geom_density(aes(linetype = r)) +
    labs(x = "寄付控除の効果（リターン）", y = "密度", linetype = "寄付申請") +
    ggtemp()
```

寄付控除を申請したグループの方が、価格弾力性は弾力的であり、申請の寄付に対する効果は大きい。
これは寄付が多いほど、申請したときの税負担が軽くなることを反映している。

ちなみに、関心のあるパラメータは密接に関連しているものである。
寄付額のモデル式から申請したときとそうでない時の寄付額（それぞれ、$\ln g_{i1}$と$\ln g_{i0}$）は以下のように書ける。
\begin{align}
  \begin{cases}
    \ln g_{i1} = \epsilon_{pi} \ln (1 - \tau(y_i)) + 0.4 \ln y_i + u_i  \\
    \ln g_{i0} =  0.4 \ln y_i + u_i  \\
  \end{cases}
\end{align}
ここから、申請による寄付の効果（リターン）を示すパラメータ$\beta_i = \ln g_{i1} - \ln g_{i0}$は
$$ \beta_i = \epsilon_{pi} \ln (1 - \tau(y_i)) $$
となる。
したがって、$\beta_i$もしくは$\epsilon_{pi}$のどちらかを推定できれば、
推定できないパラメータを復元することは可能である。

ただし、個人ごとのパラメータを復元することは不可能なので、以下のような母集団レベルに関するパラメータの復元を試みる。
すなわち、弾力性の平均値と寄付控除申請の効果（リターン）の平均を推定したい。

$$ E(\epsilon_{pi}) $$
$$ E(\beta_i) = E[\epsilon_{pi} \ln (1 - \tau(y_i))] = E(\epsilon_{pi})E[\ln (1 - \tau(y_i))] $$

$\epsilon_{pi}$と$y_i$は独立に決まるので、弾力性と寄付のfirst-priceは独立に決まる。
よって、第二式の等式が成り立つ。
寄付のfirst-priceの平均値はデータから推定できるので、
$\beta_i$もしくは$\epsilon_{pi}$のどちらかを推定できれば、
推定できないパラメータを復元することは可能である。
上述のDGPで生成される二つのパラメータの平均値の真値は以下のようになる。

```{r}
tibble::tibble(beta = b, eps = eps, p = log(p)) %>%
  datasummary(
    (`控除申請の効果（リターン）` = beta) +
      (`弾力性` = eps) +
      (`控除した場合の寄付価格の対数` = p) ~
      (`平均` = mean),
    data = .,
    fmt = 4
  )
```

控除申請のリターンと弾力性は観察不可能であるが、控除した場合の寄付価格は観察可能である。
また、控除申請の効果は弾力性の平均と寄付価格の平均の積で復元できることも確認できる。

以上のパラメータに加えて、以下のようなサブグループに関するパラメータの平均を復元したい。
これが出来れば、理論的な帰結だけではなく、政策的な帰結もより直接的に得られる。
我々のやったことの価値をより強く売ることができるのではないか？

- 控除を申請したグループ：$E(\beta_i | R_i = 1)$もしくは$E(\epsilon_{pi} | R_i = 1)$
- 控除を申請しなかったグループ：$E(\beta_i | R_i = 0)$もしくは$E(\epsilon_{pi} | R_i = 0)$

以上のパラメータの真値は以下の通り

```{r}
tibble::tibble(beta = b, eps = eps, r = r, p = log(p)) %>%
  mutate(r = factor(r, labels = c("控除を申請していない", "控除を申請した"))) %>%
  datasummary(
    (`控除申請の効果（リターン）の平均` = beta) +
      (`弾力性の平均` = eps) +
      (`控除した場合の寄付価格の対数平均` = p) ~
      mean * r,
    data = .,
    fmt = 4
  )
```

## Endogenous Problem

このモデルにおいて、控除申請は申請した場合の寄付額に依存して決まるので、
申請したかどうかを示す二値変数$R_i$と寄付の相対価格は$\ln p_i$は誤差項$u$と相関する（内生変数）。

```{r}
tibble(r, u) %>%
  mutate(r = factor(r, labels = c("控除を申請していない", "控除を申請した"))) %>%
  ggplot(aes(x = u)) +
    geom_density(aes(linetype = r)) +
    labs(x = "寄付の誤差項", y = "密度", linetype = "寄付控除") +
    ggtemp()

tibble(p = dt$real_p, u) %>%
  mutate(g = ntile(u, 100)) %>%
  group_by(g) %>%
  summarize_at(vars(p, u), list(~mean(.))) %>%
  ggplot(aes(x = u, y = p)) +
    geom_point() +
    labs(x = "寄付の誤差項", y = "寄付の相対価格") +
    ggtemp()
```

一つ目のグラフは寄付控除申請の有無でサブグループで分けて誤差項の分布を推定したものである。
控除を申請しているグループの方が価格や所得で説明できない要素で寄付額を増やしていることがわかる。
これは寄付控除を申請する場合の税負担の式からも明らかである。
二つ目のグラフは誤差項を基準にデータを100分割にして、寄付の相対価格と誤差項の平均をプロットしたものである。
価格や所得で説明できない要素で寄付額を増やしている人ほど、寄付控除を申請する傾向にあるので、
この傾向は、価格や所得で説明できない要素で寄付額を増やしている人ほど、
申請によって寄付の相対価格を減らしている。

# Identification of $\beta_i$

## Biased OLSE

控除申請の効果$\beta_i$の推定を考える。
単純化のために以下の推定式を考える。

$$ \ln g_i = \alpha + \beta_i R_i + e_i $$

ここで、$\beta_i = \epsilon_{pi} \ln(1 - \tau(y_i))$、
$e_i = 0.4 \cdot \ln y_i + u_i$である。
さらに、$\bar{\beta} = E(\beta)$として、
この推定式を以下のように書き換える。

$$ \ln g_i = \alpha + \bar{\beta} R_i + \{(\beta_i - \bar{\beta})R_i + e_i \} $$

よって、$\bar{\beta}$のOLSEは以下を識別する

\begin{align}
  \bar{\beta}
  &= E(\ln g_i | R_i = 1) - E(\ln g_i | R_i = 0)  \\
  &= \bar{\beta} + E(\beta_i - \bar{\beta} | R_i = 1) + \{ E(e_i|R_i = 1) - E(e_i|R_i = 0) \}
\end{align}

以下の表は$\bar{\beta}$のOLS推定値と、
その推定値の三つの要素である
$\bar{\beta}$の真値・Random coefficient modelの誤差である$E(\beta_i - \bar{\beta}|R_i = 1)$・
セレクションバイアスである$E(e_i|R_i = 1) - E(e_i|R_i = 0)$を示した。

```{r}
rawvalue <- function(x) x

olse <- mean(dt[dt$r == 1,]$ln_g) - mean(dt[dt$r == 0,]$ln_g)
true <- mean(b)
bias1 <- mean(b[r == 1] - mean(b))
bias2 <- mean(0.4 * log(y[r == 1]) + u[r == 1]) -
  mean(0.4 * log(y[r == 0]) + u[r == 0])

tibble(olse, true, bias1, bias2) %>%
  datasummary(
    (`OLS推定値` = olse) +
      (`申請平均効果の真値` = true) +
      (`Random Coefficient Modelによるバイアス` = bias1) +
      (`セレクションバイアス` = bias2) ~
      (` ` = rawvalue),
    data = ., fmt = 4
  )
```

表を見てわかるように、OLS推定値は申請平均効果の真値と二つのバイアスの和で得られる。
セレクションバイアスは所得効果を含んでいるが、これをコントロールしてもOLS推定量はバイアスを伴う。
以下に共変量を制御したOLS推定の結果を示す。

```{r}
estmod <- list(
  "(1)" = lm_robust(ln_g ~ r, data = dt),
  "(2)" = lm_robust(ln_g ~ r + ln_y, data = dt),
  "(3)" = lm_robust(ln_g ~ r + ln_y + log(p), data = dt)
)

estmod %>%
  modelsummary(stars = TRUE, gof_omit = "R2|se", fmt = 4)
```

## 2SLS

外生変数$Z_i$で構築される操作変数$J(Z_i)$（$Cov(J(Z_i), Z_i) \neq 0$となる変数）として、
二段階推定量（2SLS）は以下のようになる。
$$
\beta_{\text{IV}}
= \frac{Cov(J(Z_i), \ln g_i)}{Cov(J(Z_i), R_i)}
= \frac{Cov(J(Z_i), \ln g_i)}{Cov(J(Z_i), P(Z_i))}
$$
ここで、$P(Z_i)$は寄付控除申請の傾向スコアである。
特に、$P(Z_i)$を操作変数とする場合、二段階推定量は
$$
\beta_{\text{IV}}
= \frac{Cov(P(Z_i), \ln g_i)}{V(P(Z_i))}
$$
となり、傾向スコアを直接説明変数として加えた場合と一致する。
以下はこの点を確認した分析である。

```{r}
stage1_bin <- glm(r ~ z, data = dt, family = binomial(link = "probit"))
estdt <- dt %>%
  modelr::add_predictions(stage1_bin, type = "link") %>%
  mutate(ps = pnorm(pred))

stage2 <- list(
  "(1)" = iv_robust(ln_g ~ r | z, data = estdt),
  "(2)" = iv_robust(ln_g ~ r | ps, data = estdt),
  "(3)" = lm_robust(ln_g ~ ps, data = estdt)
)

stage2 %>%
  modelsummary(stars = TRUE, gof_omit = "R2|se|p|statistic", fmt = 4)
```

第一列は$J(Z_i) = Z_i$とした2SLS、第二列は$J(Z_i) = P(Z_i)$とした2SLSである。
第三列は$P(Z_i)$を説明変数としたOLS推定の結果である。
先に示したように、第二列と第三列は数値的に一致している。
また、第一列と第二列も数値的に一致している。

$E(J(Z_i) e_i) = 0$を仮定する（標準的なIVの仮定）と、
上の三つの推定量は
$$
\beta_{\text{IV}}
= \frac{E(\beta_i | R_i = 1, Z_i = 1) P(1) - E(\beta_i | R_i = 1, Z_i = 0) P(0)}{P(1) - P(0)}
$$
となる。
この推定量を以下のように書き換える。
\begin{align}
  \beta_{\text{IV}}
  &= \bar{\beta}
  + \frac{E(\beta_i - \bar{\beta}|R_i = 1, Z_i = 1) P(1) - E(\beta_i - \bar{\beta}|R_i = 1, Z_i = 0) P(0)}{P(1) - P(0)} \\
  &= \bar{\beta}
  + \frac{E((\beta_i - \bar{\beta})R_i|Z_i = 1) P(1) - E((\beta_i - \bar{\beta})R_i|Z_i = 0) P(0)}{P(1) - P(0)}
\end{align}
したがって、

- $E(\beta_i | Z_i) = E(\beta_i)$ならば、$\beta_{\text{IV}} = E(\beta_i | R_i = 1)$となる
- $E((\beta_i - \bar{\beta})R_i | Z_i) = E((\beta_i - \bar{\beta})R_i)$ならば、$\beta_{\text{IV}} = \bar{\beta}$となる

```{r}
tibble(b, br = (b - mean(b)) * r, z) %>%
  mutate(z = factor(z, labels = c("Z = 0", "Z = 1"))) %>%
  select("b" = b, "(b - mean(b))*R" = br, z) %>%
  datasummary_balance(
    b ~ z,
    data = ., fmt = 4
  )
```

以上の表より、$E(\beta_i | Z_i) = E(\beta_i)$が成立しているが、
$E((\beta_i - \bar{\beta})R_i | Z_i) = E((\beta_i - \bar{\beta})R_i)$が成立しているとは言い難い。
したがって、2SLS推定量は$E(\beta_i | R_i = 1)$を識別している**はずである**。
実際に$\beta_{IV}$を以下のように計算すると、$E(\beta_i | R_i = 1)$の真値である`r mean(b[r == 1])`に近い値を取る。

```{r}
p <- estdt %>% group_by(z) %>% {unique(.$ps)}
itty <- mean(b[r == 1 & z == 1]) * p[1] - mean(b[r == 1 & z == 0]) * p[2]
ittd <- p[1] - p[2]
iv <- itty / ittd

tibble(itty, ittd, iv) %>%
  datasummary(
    (`IVの分子（ITT-effect on log(g)）` = itty) +
      (`IVの分母（ITT-effect on R）` = ittd) +
      (`IV推定値` = iv) ~ (` ` = rawvalue),
    data = ., fmt = 4
  )
```

$E(\beta_i | Z_i) = E(\beta_i)$が仮定できないとき、別の仮定を用いることで別のパラメータを識別できる。
ここで、$R_i(Z_i)$という変数を導入する。これは$Z_i = z$のとき、寄付控除を申請するかどうかを示す指示関数である。
たとえば、$Z_i = 1$のもとで$R_i = 1$ならば、$R_i(1) = 1$となる。これを用いて、$\beta_{IV}$の分子を以下のように書き換える。
\begin{align}
  &E(\beta_i |R_i(1) = 1) E(R_i(1)) - E(\beta_i|R_i(0) = 1) E(R_i(0)) \\
  =& E(\beta_i|R_i(1) = 1, R_i(0) = 1) P(R_i(1) = 1, R_i(0) = 1) \\
  &+ E(\beta_i|R_i(1) = 1, R_i(0) = 0) P(R_i(1) = 1, R_i(0) = 0) \\ 
  &- E(\beta_i|R_i(1) = 1, R_i(0) = 1) P(R_i(1) = 1, R_i(0) = 1) \\ 
  &- E(\beta_i|R_i(1) = 0, R_i(0) = 1) P(R_i(1) = 0, R_i(0) = 1) \\
  =& E(\beta_i|R_i(1) = 1, R_i(0) = 0) P(R_i(1) = 1, R_i(0) = 0) \\ 
  &- E(\beta_i|R_i(1) = 0, R_i(0) = 1) P(R_i(1) = 0, R_i(0) = 1) 
\end{align}
次に、$\beta_{IV}$の分母を以下のように書き換える。
\begin{align}
  E(R_i(1)) - E(R_i(0)) \\
  =& P(R_i(1) = 1, R_i(0) = 1) + P(R_i(1) = 1, R_i(0) = 0) \\
  &- P(R_i(1) = 1, R_i(0) = 1) - P(R_i(1) = 0, R_i(0) = 1) \\
  =& P(R_i(1) = 1, R_i(0) = 0) - P(R_i(1) = 0, R_i(0) = 1)
\end{align}
したがって、

- $P(R_i(1) = 0, R_i(0) = 1) = 0$ならば、$\beta_{IV} = E(\beta_i|R_i(1) = 1, R_i(0) = 0)$
- $P(R_i(1) = 1, R_i(0) = 0) = 0$ならば、$\beta_{IV} = E(\beta_i|R_i(1) = 0, R_i(0) = 1)$

```{r}
r0 <- 1 * (atr13(y) * y > atr13(y - exp(g1)) * (y - exp(g1)) + 80 - 40 * 0 + v)
r1 <- 1 * (atr13(y) * y > atr13(y - exp(g1)) * (y - exp(g1)) + 80 - 40 * 1 + v)

tibble(r0, r1) %>%
  mutate(
    r0 = factor(r0, labels = c("R(0) = 0", "R(0) = 1")),
    r1 = factor(r1, labels = c("R(1) = 0", "R(1) = 1"))
  ) %>%
  datasummary_crosstab(r0 ~ r1, data = .)
```

$Z$は申請コストを下げる方向に働くので、$P(R_i(1) = 0, R_i(0) = 1) = 0$となるはずである。
事実、上の表はその結果を示している。
したがって、$E(\beta_i|Z_i) = E(\beta_i)$が仮定できないならば、
$\beta_{IV}$は$E(\beta_i|R_i(1) = 1, R_i(0) = 0)$を識別している。
以下の表はそのパラメータの真値と他の関心のあるパラメータの真値である。

```{r}
tibble(
  ate = mean(b),
  att = mean(b[r == 1]),
  atu = mean(b[r == 0]),
  late = mean(b[r1 == 1 & r0 == 0]),
  iv = iv) %>%
  datasummary(
    (`E(b)` = ate) +
      (`E(b|R = 1)` = att) +
      (`E(b|R = 0)` = atu) +
      (`E(b|R(1) = 1, R(0) = 0)` = late) +
      (`IV推定値` = iv) ~ (` ` = rawvalue),
    data = ., fmt = 4
  )
```

したがって、$\beta_{IV}$は$E(\beta_i|R_i(1) = 1, R_i(0) = 0)$ではなく、$E(\beta_i | R_i = 1)$に非常に近い値を取る。
最後に、共変量を加えた場合に2SLS推定値がどのように変化するかを以下に示しておく。

```{r}
ivmod <- list(
  "(1)" = ln_g ~ r | z,
  "(2)" = ln_g ~ r + ln_y | z + ln_y,
  "(3)" = ln_g ~ r + ln_y + log(p) | z + ln_y + log(p),
  "(4)" = ln_g ~ r | ps,
  "(5)" = ln_g ~ r + ln_y | ps + ln_y,
  "(6)" = ln_g ~ r + ln_y + log(p) | ps + ln_y + log(p)
)

ivmod %>%
  purrr::map(~iv_robust(., data = estdt)) %>%
  modelsummary(stars = TRUE, gof_omit = "R2|se|p|statistic", fmt = 4)
```

また、共変量と傾向スコアを説明変数に加えた場合にOLS推定値がどのように変化するかを以下に示しておく。

```{r}
est_s2mod <- list(
  "(1)" = lm_robust(ln_g ~ ps, data = estdt),
  "(2)" = lm_robust(ln_g ~ ps + ln_y, data = estdt),
  "(3)" = lm_robust(ln_g ~ ps + ln_y + log(p), data = estdt)
)

est_s2mod %>%
  modelsummary(stars = TRUE, gof_omit = "R2|se", fmt = 4)
```

共変量を加えた場合でも、操作変数の選択（$Z_i$もしくは$P(Z_i)$）で推定値は変化しない。
また、共変量と傾向スコアを説明変数に加えた場合、2SLS推定値と異なるが、その誤差は無視できるほどに小さい。

## Control Function Approach

内生変数$R_i$が以下のようにモデル化できると仮定する（通常の2SLSの同じ）。

$$ R_i = \delta Z_i + \eta_i,\quad E(\eta_i | Z_i) = 0 $$

さらに、観察できない$\beta_i - \bar{\beta}$と$u_i$について以下のような仮定を置く

$$ e_i = \gamma_1 \eta_i + \tilde{e}_i, \quad E(\eta_i \tilde{e}_i) = 0 $$
$$ (\beta_i - \bar{\beta}) = \gamma_2 \eta_i + \tilde{\beta}_i,\quad E(\eta_i \tilde{\beta}_i) = 0$$

以上の二つの式をアウトカムの推定式に代入すると、

$$ \ln g_i = \bar{\beta} R_i + \gamma_2 R_i \eta_i + \gamma_1 \eta_i + \{ \tilde{\beta}_i R_i + \tilde{e}_i \} $$

この推定式において、$R_i$は新たな誤差項$\tilde{\beta}_i R_i + \tilde{e}_i$と独立である。
なぜなら、$E(R_i \tilde{\beta}_i) = E(R_i \tilde{e}_i) = 0$だからである。

- $E(R_i \tilde{\beta}_i) = \delta E(Z_i \tilde{\beta}_i) + E(\eta_i \tilde{\beta}_i)$と書ける。ここで、$E(Z_i \tilde{\beta}_i) = 0$である。なぜなら、$E(Z_i e_i) = \gamma_2 E(Z_i \eta_i) + E(Z_i \tilde{\beta}_i)$であり、標準的なIVの仮定より、$E(Z_i e_i) = E(Z_i \eta_i) = 0$であるので、$E(Z_i \tilde{\beta}_i) = 0$となる。また、仮定より、$E(\eta_i \tilde{\beta}_i) = 0$なので、$E(R_i \tilde{\beta}_i) = 0$
- $E(R_i \tilde{e}_i) = \delta E(Z_i \tilde{e}_i) + E(\eta_i \tilde{e}_i)$と書ける。ここで、$E(Z_i \tilde{e}_i) = 0$である。なぜなら、$E(Z_i e_i) = \gamma_1 E(Z_i \eta_i) + E(Z_i \tilde{e}_i)$であり、標準的なIVの仮定より、$E(Z_i e_i) = E(Z_i \eta_i) = 0$であるので、$E(Z_i \tilde{e}_i) = 0$となる。また、仮定より、$E(\eta_i \tilde{e}_i) = 0$なので、$E(R_i \tilde{e}_i) = 0$

したがって、$R_i$の推定式の残差を説明変数に加えることで、$\bar{\beta}$が識別できる。

```{r}
stage1 <- r ~ z
stage1_ols <- lm_robust(stage1, data = dt)
stage1_bin <- glm(stage1, data = dt, family = binomial(link = "probit"))

estdt <- dt %>%
  modelr::add_residuals(stage1_ols) %>%
  modelr::add_predictions(stage1_bin, type = "link") %>%
  mutate(
    ps = pnorm(pred),
    gr = r * (dnorm(pred) / ps) - (1 - r) * (dnorm(-pred) / pnorm(-pred))
  )

stage2 <- list(
  "(1)" = ln_g ~ r + resid,
  "(2)" = ln_g ~ r + resid + r:resid,
  "(3)" = ln_g ~ r + gr,
  "(4)" = ln_g ~ r + gr + r:gr
)

stage2 %>%
  purrr::map(~lm_robust(., data = estdt)) %>%
  modelsummary(stars = TRUE, gof_omit = "R2|se|p|statistic", fmt = 4)
```


```{r}
stage1 <- r ~ z + log(p) + ln_y
est_stage1 <- glm(stage1, data = dt, family = binomial(link = "probit"))
summary(est_stage1)
```

```{r}
# propensity score and generalized residuals
dt$linps <- predict(est_stage1, newdata = dt, type = "link")
dt$ps <- pnorm(dt$linps)
dt$gr <- with(dt, r * dnorm(linps) / ps + (1 - r) * dnorm(-linps) / (1 - ps))

# 2SLS
tsls <- ln_g ~ -1 + r:log(p) + ln_y | ps:p + ln_y
estimatr::iv_robust(tsls, dt) %>% summary

# Control Function
cf <- ln_g ~ -1 + r:log(p) + ln_y + gr + gr:r + gr:log(p) + gr:log(real_p)
estimatr::lm_robust(cf, dt) %>% summary

# Control Function for R = 1
cf1 <- ln_g ~ -1 + log(p) + ln_y + gr
estimatr::lm_robust(cf1, subset(dt, r == 1)) %>% summary

# Control Function for R = 0
estimatr::lm_robust(cf1, subset(dt, r == 0)) %>% summary()
```